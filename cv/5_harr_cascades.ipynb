{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haar Cascades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The \"old school\" but efficient way of doing object detection.\n",
    "- Specifically famous for face detection.\n",
    "- While deep learning (CNNs) has taken over for accuracy, Haar Cascades are still used today in systems with low processing power (like webcams or microcontrollers).\n",
    "- based on **Viola-Jones algorithm**\n",
    "\n",
    "### Calculating Haar Features\n",
    "A Haar feature is essentially calculations that are performed on adjacent rectangular regions at a specific location in a detection window. \n",
    "\n",
    "The algorithm uses three types of features: <br><br>\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:684/format:webp/1*yl-BqUzycbyfhPAzwWOddQ.png\" width=\"250\">\n",
    "\n",
    "The sum of the pixels in the white area are substracted from the sum of the pixels in the black area. \n",
    "\n",
    "### The Integral Image (or Summed Area Table)\n",
    "Summing up pixel values is the most computationally expensive part. The Integral Image makes it a lot faster. At any point $(x, y)$, the value in the integral image is the sum of all pixels to the left and above it.\n",
    "\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:864/format:webp/1*dy_lV_6Ne8KSeOWoWB1kAw.png\" width=\"250\">\n",
    "\n",
    "- **The Result**: To calculate the sum of any rectangle, one only needs to look at four corner points in the table: $D - B - C + A$.\n",
    "- **Complexity**: This takes $O(1)$ time. This means the computer can calculate the \"score\" for a tiny eye-feature just as fast as a giant torso-feature.\n",
    "\n",
    "### Adaboost (Adaptive boosting) training - picking the best features\n",
    "Adaboost essentially chooses the best features and trains the classifiers to use them. It uses a combination of “weak classifiers” to create a “strong classifier” that the algorithm can use to detect objects.\n",
    "\n",
    "- It evaluates every single feature on a training set of positive (faces) and negative (non-faces) images. \n",
    "- It picks the feature that has the lowest error rate. \n",
    "- It repeats this, but gives more \"weight\" to the images that the previous features got wrong. \n",
    "- In the end, it narrows down features to a few hundred that actually matter.\n",
    "\n",
    "### Cascading classifiers\n",
    "Even with a few hundred \"Strong\" features, it's too much work to check every pixel of a 4K video. The Cascade is a degenerate tree:\n",
    "- Stage 0: Checks only 2 features (e.g., \"Is there a dark horizontal line across the eyes?\").\n",
    "- Reject: If No, it kills the window immediately (happens for ~50% of the image).\n",
    "- Stage 1: Checks 10 more features.\n",
    "- Stage 20: Checks the most complex features.\n",
    "\n",
    "### Disadvantages\n",
    "- **Rotation Invariance**: Haar Cascades are very bad at detecting tilted or upside-down faces. They expect the eyes to be horizontal.\n",
    "- **Occlusion**: If you cover one eye or half the face, the \"Cascade\" often fails early because it can't find the primary features.\n",
    "- **Lighting**: They are highly sensitive to lighting because they rely on simple intensity differences. A shadow across half your face can break the detection.\n",
    "- **False Positives**: In complex backgrounds (like a forest), random shadows can accidentally trigger enough features to \"look\" like a face to the cascade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# 1. Load the pre-trained Haar Cascade file\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# 2. Load an image and convert to Grayscale (Haar works on light/dark, so color isn't needed)\n",
    "img = cv2.imread('photo.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 3. Detect faces\n",
    "# scaleFactor: how much the image size is reduced at each image scale\n",
    "# minNeighbors: how many 'votes' a region needs to be called a face\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "# 4. Draw rectangles around the faces\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "cv2.imshow('Face Detection', img)\n",
    "cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
